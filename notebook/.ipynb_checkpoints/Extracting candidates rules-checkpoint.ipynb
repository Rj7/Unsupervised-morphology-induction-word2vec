{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict, Counter\n",
    "import gensim, logging\n",
    "import nltk\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.similarities.index import AnnoyIndexer\n",
    "from multiprocessing import Process, Pool\n",
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_corpus = []\n",
    "# for file in nltk.corpus.gutenberg.fileids():\n",
    "#     with open((nltk.corpus.gutenberg.words(file).fileid.path), 'r') as f:\n",
    "#         for line in f.readlines():\n",
    "#             try:\n",
    "#                 total_corpus.append(line.split())\n",
    "#             except:\n",
    "#                 print (\"hi\")\n",
    "#                 print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(emma.fileid.path) as f:\n",
    "#     for line in f.readlines():\n",
    "#         print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7811"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(set(emma))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patterns_in_words(patterns,pattern_counter,word1,word2,max_len):\n",
    "    i = 1\n",
    "    while(word1[:i] == word2[:i]):\n",
    "        i = i + 1\n",
    "    if i != 1 and i > max(len(word1[i-1:]), len(word2[i-1:])) < max_len:\n",
    "        pattern_counter[(\"suffix\",word1[i-1:], word2[i-1:])] += 1\n",
    "        if (\"suffix\",word1[i-1:], word2[i-1:]) in patterns:\n",
    "            patterns[(\"suffix\",word1[i-1:], word2[i-1:])].append((word1, word2))\n",
    "        else:\n",
    "            patterns[(\"suffix\",word1[i-1:], word2[i-1:])] = [(word1, word2)]\n",
    "#         patterns[(\"suffix\",word1[i-1:], word2[i-1:], word1, word2)] += 1\n",
    "    i = 1\n",
    "    while(word1[-i:] == word2[-i:]):\n",
    "        i = i + 1\n",
    "    if i != 1 and max(len(word1[:-i+1]), len(word2[:-i+1])) < max_len:\n",
    "        pattern_counter[(\"prefix\",word1[:-i+1], word2[:-i+1])] += 1\n",
    "        if (\"prefix\",word1[:-i+1], word2[:-i+1]) in patterns:\n",
    "            patterns[(\"prefix\",word1[:-i+1], word2[:-i+1])].append((word1, word2))\n",
    "        else:\n",
    "            patterns[(\"prefix\",word1[:-i+1], word2[:-i+1])] = [(word1, word2)]\n",
    "#         patterns[(\"prefix\",word1[:-i+1], word2[:-i+1], word1, word2)] += 1\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pattern_dict(vocab,max_len = 6):\n",
    "    patterns  = defaultdict(int)\n",
    "    pattern_counter = Counter()\n",
    "    for word in vocab:\n",
    "        for second_word in vocab:\n",
    "            if word != second_word:\n",
    "                extract_patterns_in_words(patterns,pattern_counter,word,second_word,max_len)\n",
    "    return patterns, pattern_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 664 ms, total: 1min 28s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%time patterns,pattern_counter = build_pattern_dict(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1177224"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Common patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('suffix', '', 's'), 700),\n",
       " (('suffix', 's', ''), 700),\n",
       " (('suffix', 'ed', 'ing'), 365),\n",
       " (('suffix', 'ing', 'ed'), 365),\n",
       " (('suffix', '', 'ed'), 324),\n",
       " (('suffix', 'ed', ''), 324),\n",
       " (('suffix', '', 'ing'), 305),\n",
       " (('suffix', 'ing', ''), 305),\n",
       " (('suffix', '', 'ly'), 275),\n",
       " (('suffix', 'ly', ''), 275)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Common Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('prefix', 'the', 'nur'), 1),\n",
       " (('prefix', 'stai', 'a'), 1),\n",
       " (('prefix', 'rod', 'Whil'), 1),\n",
       " (('prefix', 'usag', 'Non'), 1),\n",
       " (('suffix', 'e', 'tled'), 1),\n",
       " (('prefix', 'seem', 'soul'), 1),\n",
       " (('prefix', 'ha', 'telli'), 1),\n",
       " (('prefix', 'Te', 'frow'), 1),\n",
       " (('prefix', 'vow', 'prais'), 1),\n",
       " (('prefix', 'misse', 'fiel'), 1),\n",
       " (('prefix', 'poore', 'you'), 1),\n",
       " (('prefix', 'Fin', 'war'), 1),\n",
       " (('prefix', 'pull', 'see'), 1),\n",
       " (('prefix', 'Tak', 'lat'), 1),\n",
       " (('prefix', 'Hodge', 'boy'), 1),\n",
       " (('suffix', 're', 'pe'), 1),\n",
       " (('prefix', 'hurry', 'Rous'), 1),\n",
       " (('prefix', 'stair', 'curl'), 1),\n",
       " (('prefix', 'wors', 'undon'), 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_counter.most_common()[:-20:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_patterns = Counter()\n",
    "for key in pattern_counter:\n",
    "    if pattern_counter[key] > 50:\n",
    "        common_patterns[key] = pattern_counter[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('suffix', '', 's'), 700),\n",
       " (('suffix', 's', ''), 700),\n",
       " (('suffix', 'ed', 'ing'), 365),\n",
       " (('suffix', 'ing', 'ed'), 365),\n",
       " (('suffix', '', 'ed'), 324),\n",
       " (('suffix', 'ed', ''), 324),\n",
       " (('suffix', 'ing', ''), 305),\n",
       " (('suffix', '', 'ing'), 305),\n",
       " (('suffix', '', 'ly'), 275),\n",
       " (('suffix', 'ly', ''), 275)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_patterns.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 268 ms, sys: 8 ms, total: 276 ms\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%time word_vectors = KeyedVectors.load_word2vec_format('/home/raja/GoogleNews-vectors-negative300.bin.gz', binary=True, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_vector(word_vectors, dimensions=300):\n",
    "    fname = '../data/annoy.index'\n",
    "    # Persist index to disk\n",
    "    if os.path.exists(fname):\n",
    "        annoy_index = AnnoyIndexer()\n",
    "        annoy_index.load(fname)\n",
    "        annoy_index.model = word_vectors\n",
    "    else:\n",
    "        annoy_index = AnnoyIndexer(word_vectors, dimensions)\n",
    "    annoy_index.save(fname)\n",
    "    return annoy_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 64 ms, total: 15.6 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "word_vectors.init_sims()\n",
    "%time annoy_index = index_vector(word_vectors=word_vectors, dimensions=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dry run to make sure both indices are fully in RAM\n",
    "vector = word_vectors.wv.syn0norm[1119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('successful', 1.0),\n",
       " ('success', 0.5622546076774597),\n",
       " ('profitable', 0.4990977644920349),\n",
       " ('successes', 0.49772655963897705),\n",
       " ('accomplished', 0.49642592668533325)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar([vector], topn=5,indexer=annoy_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('successful', 0.9999998807907104),\n",
       " ('success', 0.6167577505111694),\n",
       " ('unsuccessful', 0.501818060874939),\n",
       " ('profitable', 0.4981939196586609),\n",
       " ('successes', 0.49544286727905273)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar([vector], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
