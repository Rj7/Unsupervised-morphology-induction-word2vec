{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict, Counter\n",
    "import gensim, logging\n",
    "import nltk\n",
    "from gensim import matutils\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.similarities.index import AnnoyIndexer\n",
    "from multiprocessing import Process, Pool\n",
    "import os\n",
    "import collections\n",
    "from random import shuffle\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from scipy.stats import spearmanr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.wrappers import FastText\n",
    "import string\n",
    "from numpy import dot, zeros, dtype, float32 as REAL,\\\n",
    "    double, array, vstack, fromstring, sqrt, newaxis,\\\n",
    "    ndarray, sum as np_sum, prod, ascontiguousarray,\\\n",
    "    argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spearman Correlation for different word embeddings on Standford rare word dataset\n",
    "word2vec: (0.2516646845987402, 1825)\n",
    "\n",
    "word2vec with morph 100000: (0.24562283855541628, 1988)\n",
    "\n",
    "glove6B 50dimensions (0.26159587465252532, 1782)\n",
    "\n",
    "glove6B 50dims with morph 100000 : (0.25914850463800143, 1996) (0.229)\n",
    "\n",
    "glove 100dimensions (0.2136083090117197, 1782)\n",
    "\n",
    "glove 200dimensions (0.17667532980978479, 1782)\n",
    "\n",
    "glove 300dimensions (0.15571816294824803, 1782)\n",
    "\n",
    "glove 42B 300dimensions \n",
    "\n",
    "Fasttext: wiki.en.vec (0.3675364161772991, 1990)\n",
    "\n",
    "Fasttext:wiki-news-300d-1M.vec (0.29925381437203319, 1966)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.6 s, sys: 2.45 s, total: 28.1 s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%time fasttext =KeyedVectors.load_word2vec_format('/home/raja/models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fasttext.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_file = '../data/norm_graph_100000_17168'\n",
    "graph_handle = open(graph_file, \"rb\")\n",
    "G = pickle.load(graph_handle)\n",
    "graph_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('autistic',\n",
       " 'autism',\n",
       " ('antagonistic', 'antagonism'),\n",
       " {'cos': 0.5927902460098267, 'morp_rule': ('suffix', 'tic', 'm'), 'rank': 2})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(G.edges(keys=True, data=True))[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_rules = {}\n",
    "for edge in G.edges(keys=True, data=True):\n",
    "    morph_rules[edge[3]['morp_rule']] = edge[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spearman_corr(word_vectors):\n",
    "    rw = pd.read_csv('../dataset/rw/rw.txt', header=None,sep='\\t')\n",
    "    rare_word_pair = []\n",
    "    for index, row in rw.iterrows():\n",
    "        rare_word_pair.append((row[0], row[1]))\n",
    "    corr_list = []\n",
    "    for word1,word2 in rare_word_pair:\n",
    "        try:\n",
    "            cor, p = spearmanr(word_vectors.wv[word1], word_vectors.wv[word2])\n",
    "            corr_list.append(cor)\n",
    "        except Exception as e:\n",
    "            if word1 in word_vectors.vocab:\n",
    "                match, word2_vec = get_oov_vector(word2)\n",
    "                if match:\n",
    "                    cor, p = spearmanr(word_vectors.wv[word1],word2_vec)\n",
    "                    print (word1,cor)\n",
    "                    corr_list.append(cor)\n",
    "            elif word2 in word_vectors.vocab:\n",
    "                match, word1_vec = get_oov_vector(word1)\n",
    "                if match:\n",
    "                    cor, p = spearmanr(word_vectors.wv[word2],word1_vec)\n",
    "                    print (word2,cor)\n",
    "                    corr_list.append(cor)\n",
    "    return np.mean(corr_list), len(corr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oov_vector(word):\n",
    "    new_word = (False, 0, ())\n",
    "    mean = []\n",
    "    for rule in morph_rules:\n",
    "        candidate_word = apply_rule(rule, word)\n",
    "        if candidate_word and candidate_word in fasttext.vocab:\n",
    "            if fasttext.vocab[candidate_word].count > new_word[1]:\n",
    "                new_word = (candidate_word, fasttext.vocab[candidate_word].count, morph_rules[rule])\n",
    "    if new_word[0]:\n",
    "        print (word, new_word)\n",
    "        mean.append(fasttext[new_word[2][0]] * 1)\n",
    "        mean.append(fasttext[new_word[2][1]] * -1)\n",
    "        mean.append(fasttext[new_word[0]] * 1)\n",
    "        mean = matutils.unitvec(array(mean).mean(axis=0)).astype(REAL)\n",
    "        return True, mean\n",
    "    else:\n",
    "        return False, []\n",
    "#             print (\"new word\",new_word, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rule(rule, word):\n",
    "    if rule[0] == 'suffix':\n",
    "        if word[::-1].startswith(rule[1][::-1]):\n",
    "            return word[::-1].replace(rule[1][::-1], rule[2][::-1], 1)[::-1]\n",
    "    else:\n",
    "        if word.startswith(rule[1]):\n",
    "            return word.replace(rule[1], rule[2], 1)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2258053340180437, 2034)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spearman_corr(fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "disjoined = fasttext.wv['disrespect'] - fasttext.wv['respect'] + fasttext.wv['join']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
